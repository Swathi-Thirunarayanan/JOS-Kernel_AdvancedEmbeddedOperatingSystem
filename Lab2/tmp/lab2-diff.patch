diff --git a/conf/env.mk b/conf/env.mk
index a603f9e..2502dd5 100644
--- a/conf/env.mk
+++ b/conf/env.mk
@@ -16,5 +16,4 @@ V = @
 
 # If the makefile cannot find your QEMU binary, uncomment the
 # following line and set it to the full path to QEMU.
-#
-# QEMU=
+QEMU=/home/skoralah/qemu/bin/qemu-system-i386
diff --git a/kern/kdebug.c b/kern/kdebug.c
index 9547143..5653aa2 100644
--- a/kern/kdebug.c
+++ b/kern/kdebug.c
@@ -179,7 +179,13 @@ debuginfo_eip(uintptr_t addr, struct Eipdebuginfo *info)
 	//	Look at the STABS documentation and <inc/stab.h> to find
 	//	which one.
 	// Your code here.
-
+ 
+//	If *region_left > *region_right, then 'addr' is not contained in any
+//	matching stab.
+		stab_binsearch(stabs, &lline, &rline, N_SLINE, addr);
+                 if(lline > rline)
+                 return -1;
+		 info->eip_line = stabs[rline].n_desc;
 
 	// Search backwards from the line number for the relevant filename
 	// stab.
diff --git a/kern/monitor.c b/kern/monitor.c
index e137e92..77c4ec2 100644
--- a/kern/monitor.c
+++ b/kern/monitor.c
@@ -24,6 +24,7 @@ struct Command {
 static struct Command commands[] = {
 	{ "help", "Display this list of commands", mon_help },
 	{ "kerninfo", "Display information about the kernel", mon_kerninfo },
+	{ "backtrace", "Display function backtrace", mon_backtrace },
 };
 
 /***** Implementations of basic kernel monitor commands *****/
@@ -57,7 +58,16 @@ mon_kerninfo(int argc, char **argv, struct Trapframe *tf)
 int
 mon_backtrace(int argc, char **argv, struct Trapframe *tf)
 {
-	// Your code here.
+	uint32_t* p=(uint32_t *) read_ebp();
+	cprintf("Stack backtrace:\n");
+	while(p)
+	{
+	 	struct Eipdebuginfo info;
+		cprintf("ebp %08x eip %08x args %08x %08x %08x %08x %08x\n",p, *(p+1),*(p+2),*(p+3),*(p+4),*(p+5),*(p+6));
+		debuginfo_eip(*(p+1), &info);
+		cprintf("\t%s:%d : %.*s+%u\n",info.eip_file, info.eip_line, info.eip_fn_namelen, info.eip_fn_name, (*(p+1)-info.eip_fn_addr));
+		p=(uint32_t*)*p;
+	}
 	return 0;
 }
 
diff --git a/kern/pmap.c b/kern/pmap.c
index 727ea68..82e7deb 100644
--- a/kern/pmap.c
+++ b/kern/pmap.c
@@ -49,11 +49,14 @@ i386_detect_memory(void)
 	else
 		totalmem = basemem;
 
-	npages = totalmem / (PGSIZE / 1024);
-	npages_basemem = basemem / (PGSIZE / 1024);
-
-	cprintf("Physical memory: %uK available, base = %uK, extended = %uK\n",
-		totalmem, basemem, totalmem - basemem);
+	npages = totalmem / (PGSIZE / 1024); //32768
+	npages_basemem = basemem / (PGSIZE / 1024);//160
+
+	cprintf("Physical memory: %uK available, base = %uK, extended = %uK, npages=%u ,npages_basemem=%u \n",
+		totalmem, basemem, totalmem - basemem, npages, npages_basemem);
+cprintf("r=%d\n", NVRAM_BASELO);
+cprintf("kernbase=%u\n", KERNBASE);
+	
 }
 
 
@@ -102,9 +105,19 @@ boot_alloc(uint32_t n)
 	// to a multiple of PGSIZE.
 	//
 	// LAB 2: Your code here.
-
-	return NULL;
-}
+	cprintf("boot_allocated memory at %x\n", nextfree);
+	cprintf("Next memory at %x\n", ROUNDUP((char *) (nextfree+n), PGSIZE));
+	if (n>0) {
+		char *temp = nextfree;
+		nextfree = ROUNDUP((char *) (nextfree+n), PGSIZE);
+		return temp;
+	} 
+	if ((uint32_t)nextfree > KERNBASE + npages*PGSIZE){
+	panic ("boot_alloc failed - Out of memory");
+	}
+	else
+	return nextfree;
+	}
 
 // Set up a two-level page table:
 //    kern_pgdir is its linear (virtual) address of the root
@@ -125,7 +138,7 @@ mem_init(void)
 	i386_detect_memory();
 
 	// Remove this line when you're ready to test this function.
-	panic("mem_init: This function is not finished\n");
+	//panic("mem_init: This function is not finished\n");
 
 	//////////////////////////////////////////////////////////////////////
 	// create initial page directory.
@@ -140,6 +153,7 @@ mem_init(void)
 
 	// Permissions: kernel R, user R
 	kern_pgdir[PDX(UVPT)] = PADDR(kern_pgdir) | PTE_U | PTE_P;
+	cprintf("UVPT=%x\n", UVPT);
 
 	//////////////////////////////////////////////////////////////////////
 	// Allocate an array of npages 'struct PageInfo's and store it in 'pages'.
@@ -148,7 +162,11 @@ mem_init(void)
 	// array.  'npages' is the number of physical pages in memory.  Use memset
 	// to initialize all fields of each struct PageInfo to 0.
 	// Your code goes here:
-
+	pages = (struct PageInfo *) boot_alloc(sizeof(struct PageInfo) * npages);
+    	memset(pages, 0, sizeof(struct PageInfo) * npages);
+	//pages ==> Starting address of memory to be filled
+	//0   ==> Value to be filled
+	//sizeof(struct PageInfo) * npages   ==> Number of bytes to be filled starting from pages
 
 	//////////////////////////////////////////////////////////////////////
 	// Now that we've allocated the initial kernel data structures, we set
@@ -172,7 +190,7 @@ mem_init(void)
 	//      (ie. perm = PTE_U | PTE_P)
 	//    - pages itself -- kernel RW, user NONE
 	// Your code goes here:
-
+	boot_map_region(kern_pgdir, UPAGES, PTSIZE, PADDR(pages), PTE_U | PTE_P);
 	//////////////////////////////////////////////////////////////////////
 	// Use the physical memory that 'bootstack' refers to as the kernel
 	// stack.  The kernel stack grows down from virtual address KSTACKTOP.
@@ -182,9 +200,13 @@ mem_init(void)
 	//     * [KSTACKTOP-PTSIZE, KSTACKTOP-KSTKSIZE) -- not backed; so if
 	//       the kernel overflows its stack, it will fault rather than
 	//       overwrite memory.  Known as a "guard page".
+	//	To guard a stack
+	//	growing off the stack page, xv6 places a guard page right below the stack. The guard
+	//	page is not mapped and so if the stack runs off the stack page, the hardware will gen-
+	//	erate an exception because it cannot translate the faulting address.
 	//     Permissions: kernel RW, user NONE
 	// Your code goes here:
-
+	boot_map_region(kern_pgdir, KSTACKTOP-KSTKSIZE, KSTKSIZE, PADDR(bootstack), PTE_W | PTE_P);
 	//////////////////////////////////////////////////////////////////////
 	// Map all of physical memory at KERNBASE.
 	// Ie.  the VA range [KERNBASE, 2^32) should map to
@@ -193,7 +215,7 @@ mem_init(void)
 	// we just set up the mapping anyway.
 	// Permissions: kernel RW, user NONE
 	// Your code goes here:
-
+	boot_map_region(kern_pgdir, KERNBASE, 0xFFFFFFFF-KERNBASE, 0, PTE_W | PTE_P);
 	// Check that the initial page directory has been set up correctly.
 	check_kern_pgdir();
 
@@ -252,10 +274,38 @@ page_init(void)
 	// NB: DO NOT actually touch the physical memory corresponding to
 	// free pages!
 	size_t i;
+	// 0xA0
+	size_t io_hole_begin = IOPHYSMEM / PGSIZE;
+	// 0x100
+	size_t io_hole_end = ROUNDUP(EXTPHYSMEM, PGSIZE) / PGSIZE;
+	size_t kernel_end = io_hole_end + (size_t) (boot_alloc(0) - KERNBASE) / PGSIZE;
+	page_free_list = NULL;
+
+	// i < 0x40FF
 	for (i = 0; i < npages; i++) {
-		pages[i].pp_ref = 0;
-		pages[i].pp_link = page_free_list;
-		page_free_list = &pages[i];
+		// 1)
+		if (i == 0) {
+			pages[i].pp_ref = 1;
+			pages[i].pp_link = NULL;
+		// 2) i < 0xA0
+		} else if (i < npages_basemem) {
+			pages[i].pp_ref = 0;
+			pages[i].pp_link = page_free_list;
+			page_free_list = &pages[i];
+		// 3) 0xA0 <= i < 0x100
+		} else if (io_hole_begin <= i && i < io_hole_end) {
+			pages[i].pp_ref = 1;
+			pages[i].pp_link = NULL;
+		// 4) 0x100 <= i < 0x400 (0xF0400000)
+		} else if (io_hole_end <= i && i < kernel_end) {
+			pages[i].pp_ref = 1;
+			pages[i].pp_link = NULL;
+		// 4) 0x400 <= i
+		} else {
+			pages[i].pp_ref = 0;
+			pages[i].pp_link = page_free_list;
+			page_free_list = &pages[i];
+		}
 	}
 }
 
@@ -271,13 +321,26 @@ page_init(void)
 // Returns NULL if out of free memory.
 //
 // Hint: use page2kva and memset
+
 struct PageInfo *
 page_alloc(int alloc_flags)
 {
-	// Fill this function in
-	return 0;
-}
+	struct PageInfo *page;
+	
+	if (page_free_list!=NULL){
+	page = page_free_list;
+	page_free_list = page->pp_link;
+	page->pp_link = NULL;
+	
+	if (alloc_flags & ALLOC_ZERO) {
+		memset(page2kva(page), '\0', PGSIZE);
+	}
+	return page;
+	}
+	return NULL;
 
+	
+}
 //
 // Return a page to the free list.
 // (This function should only be called when pp->pp_ref reaches 0.)
@@ -288,8 +351,16 @@ page_free(struct PageInfo *pp)
 	// Fill this function in
 	// Hint: You may want to panic if pp->pp_ref is nonzero or
 	// pp->pp_link is not NULL.
+	if (pp->pp_ref!= 0 || pp->pp_link != NULL) {
+		panic("Page Free Failed: Tried to free page having either reference count>0 or linked");
+		
+	}
+
+	pp->pp_link = page_free_list;
+	page_free_list = pp;
 }
 
+
 //
 // Decrement the reference count on a page,
 // freeing it if there are no more refs.
@@ -323,12 +394,41 @@ page_decref(struct PageInfo* pp)
 // Hint 3: look at inc/mmu.h for useful macros that mainipulate page
 // table and page directory entries.
 //
+
+/******smita-code***********/
 pte_t *
 pgdir_walk(pde_t *pgdir, const void *va, int create)
 {
-	// Fill this function in
-	return NULL;
-}
+	
+	struct PageInfo *pp;
+	pte_t *pte;
+	pde_t *pde= pgdir+PDX(va); 	           //pde = &pgdir[PDX(va)]
+	if(!(*pde & PTE_P)){ 			   //If directory entry not present and create==true
+		if (create){  
+			pp=page_alloc(ALLOC_ZERO); //Allocate a physical page with ALLOC_ZERO
+			if(pp){                    // If physical page allocated
+				 
+				pp->pp_ref++;      
+				*pde=page2pa(pp)+PTE_P+PTE_W+PTE_U; //convert page address to physical address
+			      }
+			else
+				return NULL;				//if not able to allocate page
+			    }	
+				
+					                      
+	else
+		return NULL;                               //if create==false
+	}
+
+	
+	pte=KADDR(PTE_ADDR(*pde));                         //if directory entry present calculate kernel virtual address
+	
+	return (pte + PTX(va));
+		
+ }
+/***** pgdir_walk basically returns pointer to PTE for virtual address from pointer of page directory pgdir******/
+//Determines page directory index (pdx) from the linear address (va)//
+//returns the pointer to corresponding page table entry (pte[ptx]).//
 
 //
 // Map [va, va+size) of virtual address space to physical [pa, pa+size)
@@ -344,8 +444,20 @@ pgdir_walk(pde_t *pgdir, const void *va, int create)
 static void
 boot_map_region(pde_t *pgdir, uintptr_t va, size_t size, physaddr_t pa, int perm)
 {
-	// Fill this function in
+	for (int i = 0; i < size; i+= PGSIZE) {
+		pte_t *pte = pgdir_walk(pgdir, (const void *) (va + i), 1);
+		*pte = (pa + i) | perm | PTE_P;  //PTE_ADDR(pa)=physaddr(pa)&~0xFFF
+		if (!pte) {
+			panic("boot_map_region failed: out of memory");
+			return;
+			  } 
+	}
 }
+/********Maps certain area of physical memory to virtual address.******/ 
+//Loops through each physical page in the area and map them to the correct 
+//location of virtual memory using pgdir_walk//
+//Walk through [va; va + size) in PGSIZE increments filling in page table entries.//
+
 
 //
 // Map the physical page 'pp' at virtual address 'va'.
@@ -375,8 +487,24 @@ boot_map_region(pde_t *pgdir, uintptr_t va, size_t size, physaddr_t pa, int perm
 int
 page_insert(pde_t *pgdir, struct PageInfo *pp, void *va, int perm)
 {
-	// Fill this function in
+	
+
+	pte_t *pte = pgdir_walk(pgdir, va, 1);
+	
+	
+	if(pte==NULL)
+		return -E_NO_MEM;
+	pp->pp_ref++;
+	
+	if(*pte & PTE_P)
+		page_remove(pgdir,va);
+	
+	*pte = page2pa(pp) | perm | PTE_P;
+	//pgdir[PDX(va)] |= perm;	
+	
 	return 0;
+
+
 }
 
 //
@@ -390,12 +518,24 @@ page_insert(pde_t *pgdir, struct PageInfo *pp, void *va, int perm)
 //
 // Hint: the TA solution uses pgdir_walk and pa2page.
 //
+/*****smita-code**********/
 struct PageInfo *
 page_lookup(pde_t *pgdir, void *va, pte_t **pte_store)
 {
-	// Fill this function in
-	return NULL;
+	pte_t *pte = pgdir_walk(pgdir, va, 0);	//Initially not created
+	if (!(pte)) 
+	return NULL;				//page not found
+	if (pte_store!=NULL)
+		*pte_store = pte;	        //if pte_store!=0 then address of pte of page is stored
+	return pa2page(PTE_ADDR(*pte));		//page mapped at virtual address va is returned
+	
 }
+/*************Return page mapped at virtual address va********/
+//Retrieve page table entry (pte) and get the page from the last 20 bits.//
+//This function takes a virtual address and locate the PageInfo structure 
+//responsible for its memory management. pgdir_walk used to locate the page
+// table entry, and use the physical address to locate the target PageInfo.//
+
 
 //
 // Unmaps the physical page at virtual address 'va'.
@@ -415,8 +555,22 @@ page_lookup(pde_t *pgdir, void *va, pte_t **pte_store)
 void
 page_remove(pde_t *pgdir, void *va)
 {
-	// Fill this function in
+	pte_t *pte;
+	struct PageInfo *pp = page_lookup(pgdir, va, &pte);
+	if (!pp)       			//if (!pp || !(*pte & PTE_P)) : page doesnt exist
+	{
+		return ;   		// do nothing
+	}
+	else
+	{
+		page_decref(pp);  	//decrement reference count and free page table if ref count==0
+		tlb_invalidate(pgdir, va);//invalidate TLB if entry removed from page table
+		*pte = 0; 		  // making PTE corresponding to that va as zero
+	}	 
 }
+/********Unmaps the physical page at virtual address va***********/
+
+
 
 //
 // Invalidate a TLB entry, but only if the page tables being
